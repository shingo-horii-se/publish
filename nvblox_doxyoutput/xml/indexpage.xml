<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.6" xml:lang="en-US">
  <compounddef id="indexpage" kind="page">
    <compoundname>index</compoundname>
    <title>nvblox @image{inline} html docs/images/nvblox_logo_64.png &quot;nvblox_logo&quot;</title>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para><image type="latex" name="nvblox_logo_64.png" inline="yes">nvblox_logo</image>
 <image type="rtf" name="nvblox_logo_64.png" inline="yes">nvblox_logo</image>
 <image type="docbook" name="nvblox_logo_64.png" inline="yes">nvblox_logo</image>
 <image type="xml" name="nvblox_logo_64.png" inline="yes">nvblox_logo</image>
<anchor id="index_1md_C__Users_M502228_Downloads_nvblox_public_nvblox_public_README"/> Signed Distance Functions (SDFs) on NVIDIA GPUs.</para>
<para><image type="html" name="docs/images/3dmatch.gif" inline="yes"></image>
</para>
<para>A GPU SDF library which offers<itemizedlist>
<listitem><para>GPU accelerated algorithms such as:<itemizedlist>
<listitem><para>TSDF construction</para>
</listitem><listitem><para>Occupancy mapping</para>
</listitem><listitem><para>ESDF construction</para>
</listitem><listitem><para>Meshing</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>ROS 2 interface (see <ulink url="https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_nvblox">isaac_ros_nvblox</ulink>)</para>
</listitem><listitem><para>Support for storage of various voxel types, and easily extended to custom voxel types.</para>
</listitem></itemizedlist>
</para>
<para>Above we show reconstruction using data from the <ulink url="https://3dmatch.cs.princeton.edu/">3DMatch dataset</ulink>, specifically the <ulink url="http://sun3d.cs.princeton.edu/">Sun3D</ulink> <computeroutput>mit_76_studyroom</computeroutput> scene.</para>
<para><heading level="1">Table of Contents</heading>
</para>
<para><itemizedlist>
<listitem><para>nvblox<itemizedlist>
<listitem><para>Table of Contents</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Why nvblox?</para>
</listitem><listitem><para>How to use nvblox<itemizedlist>
<listitem><para>Out-of-the-box Reconstruction/ROS 2 Interface</para>
</listitem><listitem><para>Public Datasets</para>
</listitem><listitem><para>C++ Interface</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Native Installation<itemizedlist>
<listitem><para>Install dependencies</para>
</listitem><listitem><para>Build and run tests</para>
</listitem><listitem><para>Run an example</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Docker</para>
</listitem><listitem><para>Additional instructions for Jetson Xavier<itemizedlist>
<listitem><para>Open3D on Jetson</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Building for multiple GPU architectures</para>
</listitem><listitem><para>Building redistributable binaries, with static dependencies</para>
</listitem><listitem><para>License</para>
</listitem></itemizedlist>
</para>
<para><heading level="1">Why nvblox?</heading>
</para>
<para>Do we need another SDF library? That depends on your use case. If you&apos;re interested in:<itemizedlist>
<listitem><para><bold>Path planning</bold>: We provide GPU accelerated, incremental algorithms for calculating the Euclidean Signed Distance Field (ESDF) which is useful for collision checking for robotic path-planning.</para>
</listitem><listitem><para><bold>GPU acceleration</bold>: Our previous works <ulink url="https://github.com/ethz-asl/voxblox">voxblox</ulink> and <ulink url="https://github.com/ethz-asl/voxgraph">voxgraph</ulink> are used for path-planning, however utilize CPU compute only, which limits the speed of these toolboxes, and therefore the resolution of the maps they can build in real-time. nvblox is <emphasis>much</emphasis> faster.</para>
</listitem><listitem><para><bold>Jetson Platform</bold>: nvblox is written with the <ulink url="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/">NVIDIA jetson</ulink> in mind. If you want to run reconstruction on an embedded GPU, you&apos;re in the right place.</para>
</listitem></itemizedlist>
</para>
<para>Below we visualize slices through a distance function (ESDF):</para>
<para><image type="html" name="docs/images/nvblox_slice.gif" inline="yes"></image>
</para>
<para><heading level="1">How to use nvblox</heading>
</para>
<para>How use nvblox depends on what you want to do.</para>
<para><heading level="2">Out-of-the-box Reconstruction/ROS 2 Interface</heading>
</para>
<para>For users who would like to use nvblox in a robotic system or connect easily to a sensor, we suggest using our <ulink url="https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_nvblox">ROS 2 interface</ulink>.</para>
<para>The ROS 2 interface includes examples which allow you to:<itemizedlist>
<listitem><para>Build a reconstruction from a realsense camera using nvblox and NVIDIA VSLAM <ulink url="https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_nvblox/blob/main/docs/tutorial-realsense.md">here</ulink>.</para>
</listitem><listitem><para>Navigate a robot in Isaac Sim <ulink url="https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_nvblox/blob/main/docs/tutorial-isaac-sim.md">here</ulink>.</para>
</listitem><listitem><para>Combine 3D reconstruction with image segmentation with <ulink url="https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_nvblox/blob/main/docs/tutorial-human-reconstruction-realsense.md">realsense data</ulink> and in <ulink url="https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_nvblox/blob/main/docs/tutorial-human-reconstruction-isaac-sim.md">simulation</ulink>.</para>
</listitem></itemizedlist>
</para>
<para>The ROS 2 interface downloads and builds the library contained in this repository during installation, so you don&apos;t need to clone and build this repository at all.</para>
<para><heading level="2">Public Datasets</heading>
</para>
<para>If you would like to run nvblox on a public datasets, we include some executables for running reconstructions on <ulink url="https://3dmatch.cs.princeton.edu/">3DMatch</ulink>, <ulink url="https://github.com/facebookresearch/Replica-Dataset">Replica</ulink>, and <ulink url="http://redwood-data.org/indoor_lidar_rgbd/index.html">Redwood</ulink> datasets. Please see our <ref refid="md_pages_tutorial_public_datasets" kindref="compound">tutorial</ref> on running these.</para>
<para><heading level="2">C++ Interface</heading>
</para>
<para>If you want to build nvblox into a larger project, without ROS, or you would like to make modifications to nvblox&apos;s core reconstruction features, this repository contains the code you need. Our <ref refid="md_pages_tutorial_library_interface" kindref="compound">tutorial</ref> provides some brief details of how to interact with the reconstruction in c++.</para>
<para><heading level="1">Native Installation</heading>
</para>
<para>If you want to build natively, please follow these instructions. Instructions for docker are further below.</para>
<para><heading level="2">Install dependencies</heading>
</para>
<para>We depend on:<itemizedlist>
<listitem><para>gtest</para>
</listitem><listitem><para>glog</para>
</listitem><listitem><para>gflags</para>
</listitem><listitem><para>SQLite 3</para>
</listitem><listitem><para>CUDA 11.0 - 11.8 (others might work but are untested)</para>
</listitem><listitem><para>Eigen (no need to explicitly install, a recent version is built into the library)</para>
</listitem><listitem><para>stdgpu (downloaded during compilation) Please run <programlisting><codeline><highlight class="normal">sudo<sp/>apt-get<sp/>install<sp/>-y<sp/>libgoogle-glog-dev<sp/>libgtest-dev<sp/>libgflags-dev<sp/>python3-dev<sp/>libsqlite3-dev</highlight></codeline>
<codeline><highlight class="normal">cd<sp/>/usr/src/googletest<sp/>&amp;&amp;<sp/>sudo<sp/>cmake<sp/>.<sp/>&amp;&amp;<sp/>sudo<sp/>cmake<sp/>--build<sp/>.<sp/>--target<sp/>install</highlight></codeline>
</programlisting></para>
</listitem></itemizedlist>
</para>
<para><heading level="2">Build and run tests</heading>
</para>
<para><programlisting><codeline><highlight class="normal">cd<sp/>nvblox/nvblox</highlight></codeline>
<codeline><highlight class="normal">mkdir<sp/>build</highlight></codeline>
<codeline><highlight class="normal">cd<sp/>build</highlight></codeline>
<codeline><highlight class="normal">cmake<sp/>..<sp/>&amp;&amp;<sp/>make<sp/>&amp;&amp;<sp/>cd<sp/>tests<sp/>&amp;&amp;<sp/>ctest</highlight></codeline>
</programlisting></para>
<para><heading level="2">Run an example</heading>
</para>
<para>In this example we fuse data from the <ulink url="https://3dmatch.cs.princeton.edu/">3DMatch dataset</ulink>. First let&apos;s grab the dataset. Here I&apos;m downloading it to my dataset folder <computeroutput>~/datasets/3dmatch</computeroutput>. <programlisting><codeline><highlight class="normal">wget<sp/>http://vision.princeton.edu/projects/2016/3DMatch/downloads/rgbd-datasets/sun3d-mit_76_studyroom-76-1studyroom2.zip<sp/>-P<sp/>~/datasets/3dmatch</highlight></codeline>
<codeline><highlight class="normal">unzip<sp/>~/datasets/3dmatch/sun3d-mit_76_studyroom-76-1studyroom2.zip<sp/>-d<sp/>~/datasets/3dmatch</highlight></codeline>
</programlisting> Navigate to and run the <computeroutput>fuse_3dmatch</computeroutput> binary. From the nvblox base folder run <programlisting><codeline><highlight class="normal">cd<sp/>nvblox/build/executables</highlight></codeline>
<codeline><highlight class="normal">./fuse_3dmatch<sp/>~/datasets/3dmatch/sun3d-mit_76_studyroom-76-1studyroom2/<sp/>mesh.ply</highlight></codeline>
</programlisting> Once it&apos;s done we can view the output mesh using the Open3D viewer. Instructions for installing open3d-viewer can be found below. <programlisting><codeline><highlight class="normal">Open3D<sp/>mesh.ply</highlight></codeline>
</programlisting> you should see a mesh of a room: <image type="html" name="docs/images/reconstruction_in_docker_trim.png" inline="yes"></image>
</para>
<para><heading level="1">Docker</heading>
</para>
<para>We have several dockerfiles (in the <computeroutput>docker</computeroutput> subfolder) which layer on top of one another for the following purposes:</para>
<para><itemizedlist>
<listitem><para><bold>Docker.deps</bold></para>
</listitem><listitem><para>* This installs our dependencies.</para>
</listitem><listitem><para>* This is used in our CI, where the later steps (building and testing) are taken care of by Jenkins (and not docker).</para>
</listitem><listitem><para><bold>Docker.jetson_deps</bold></para>
</listitem><listitem><para>* Same as above, just on the Jetson (Jetpack 5 and above).</para>
</listitem><listitem><para><bold>Docker.build</bold></para>
</listitem><listitem><para>* Layers on top of Docker.deps.</para>
</listitem><listitem><para>* This builds our package.</para>
</listitem><listitem><para>* This is where you get off the layer train if you wanna run stuff (and don&apos;t care if it&apos;s tested).</para>
</listitem><listitem><para><bold>Docker.test</bold></para>
</listitem><listitem><para>* Layers on top of Docker.build.</para>
</listitem><listitem><para>* Runs ours tests.</para>
</listitem><listitem><para>* Useful for checking if things are likely to pass the tests in CI.</para>
</listitem></itemizedlist>
</para>
<para>We rely on nvidia docker. Install the <ulink url="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html">NVIDIA Container Toolkit</ulink> following the instructions on that website.</para>
<para>We use the GPU during build, not only at run time. In the default configuration the GPU is only used at at runtime. One must therefore set the default runtime. Add <computeroutput>&quot;default-runtime&quot;: &quot;nvidia&quot;</computeroutput> to <computeroutput>/etc/docker/daemon.json</computeroutput> such that it looks like: <programlisting><codeline><highlight class="normal">{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>&quot;runtimes&quot;:<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&quot;nvidia&quot;:<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&quot;path&quot;:<sp/>&quot;/usr/bin/nvidia-container-runtime&quot;,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&quot;runtimeArgs&quot;:<sp/>[]</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>},</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>&quot;default-runtime&quot;:<sp/>&quot;nvidia&quot;<sp/></highlight></codeline>
<codeline><highlight class="normal">}</highlight></codeline>
</programlisting> Restart docker <programlisting><codeline><highlight class="normal">sudo<sp/>systemctl<sp/>restart<sp/>docker</highlight></codeline>
</programlisting> Now Let&apos;s build Dockerfile.deps docker image. This image install contains our dependencies. <programlisting><codeline><highlight class="normal">docker<sp/>build<sp/>-t<sp/>nvblox_deps<sp/>-f<sp/>docker/Dockerfile.deps<sp/>.</highlight></codeline>
</programlisting> <blockquote><para><zwj/>In case you are running this on the Jetson, substitute the dockerfile: <computeroutput>docker/Dockerfile.jetson_deps</computeroutput> </para>
</blockquote>Now let&apos;s build the Dockerfile.build. This image layers on the last, and actually builds the nvblox library. <programlisting><codeline><highlight class="normal">docker<sp/>build<sp/>-t<sp/>nvblox<sp/>-f<sp/>docker/Dockerfile.build<sp/>.</highlight></codeline>
</programlisting> Now let&apos;s run the 3DMatch example inside the docker. Note there&apos;s some additional complexity in the <computeroutput>docker run</computeroutput> command such that we can forward X11 to the host (we&apos;re going to be view a reconstruction in a GUI). Run the container using: <programlisting><codeline><highlight class="normal">xhost<sp/>local:docker</highlight></codeline>
<codeline><highlight class="normal">docker<sp/>run<sp/>-it<sp/>--net=host<sp/>--env=&quot;DISPLAY&quot;<sp/>-v<sp/>$HOME/.Xauthority:/root/.Xauthority:rw<sp/>-v<sp/>/tmp/.X11-unix:/tmp/.X11-unix:rw<sp/>nvblox</highlight></codeline>
</programlisting> Let&apos;s download a dataset and run the example (this is largely a repeat of &quot;Run an example&quot; above). <programlisting><codeline><highlight class="normal">apt-get<sp/>update</highlight></codeline>
<codeline><highlight class="normal">apt-get<sp/>install<sp/>unzip</highlight></codeline>
<codeline><highlight class="normal">wget<sp/>http://vision.princeton.edu/projects/2016/3DMatch/downloads/rgbd-datasets/sun3d-mit_76_studyroom-76-1studyroom2.zip<sp/>-P<sp/>~/datasets/3dmatch</highlight></codeline>
<codeline><highlight class="normal">unzip<sp/>~/datasets/3dmatch/sun3d-mit_76_studyroom-76-1studyroom2.zip<sp/>-d<sp/>~/datasets/3dmatch</highlight></codeline>
<codeline><highlight class="normal">cd<sp/>nvblox/nvblox/build/executables/</highlight></codeline>
<codeline><highlight class="normal">./fuse_3dmatch<sp/>~/datasets/3dmatch/sun3d-mit_76_studyroom-76-1studyroom2/<sp/>mesh.ply</highlight></codeline>
</programlisting> Now let&apos;s visualize. From the same executable folder run: <programlisting><codeline><highlight class="normal">apt-get<sp/>install<sp/>libgl1-mesa-glx<sp/>libc++1<sp/>libc++1-10<sp/>libc++abi1-10<sp/>libglfw3<sp/>libpng16-16</highlight></codeline>
<codeline><highlight class="normal">wget<sp/>https://github.com/isl-org/Open3D/releases/download/v0.13.0/open3d-app-0.13.0-Ubuntu_20.04.deb</highlight></codeline>
<codeline><highlight class="normal">dpkg<sp/>-i<sp/>open3d-app-0.13.0-Ubuntu_20.04.deb</highlight></codeline>
<codeline><highlight class="normal">Open3D<sp/>mesh.ply</highlight></codeline>
</programlisting> to visualize on the jetson see below.</para>
<para><heading level="1">Additional instructions for Jetson Xavier</heading>
</para>
<para>These instructions are for a native build on the Jetson Xavier. You can see the instructions above for running in docker.</para>
<para>The instructions for the native build above work, with one exception:</para>
<para>We build using CMake&apos;s modern CUDA integration and therefore require a more modern version of CMAKE than (currently) ships with jetpack. Luckily the Cmake developer team provide a means obtaining recent versions of CMake through apt.</para>
<para><orderedlist>
<listitem><para>Obtain a copy of the signing key: <programlisting><codeline><highlight class="normal">wget<sp/>-qO<sp/>-<sp/>https://apt.kitware.com/keys/kitware-archive-latest.asc<sp/>|</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>sudo<sp/>apt-key<sp/>add<sp/>-</highlight></codeline>
</programlisting></para>
</listitem><listitem><para>Add the repository to your sources list and update. <programlisting><codeline><highlight class="normal">sudo<sp/>apt-add-repository<sp/>&apos;deb<sp/>https://apt.kitware.com/ubuntu/<sp/>focal<sp/>main&apos;</highlight></codeline>
<codeline><highlight class="normal">sudo<sp/>apt-get<sp/>update</highlight></codeline>
</programlisting></para>
</listitem><listitem><para>Update! <programlisting><codeline><highlight class="normal">sudo<sp/>apt-get<sp/>install<sp/>cmake</highlight></codeline>
</programlisting></para>
</listitem><listitem><para>To use the python examples, it is also necessary to make numpy play nice with the Jetson. You can do that by adding the following to your <computeroutput>~/.bashrc</computeroutput>: <programlisting><codeline><highlight class="normal">export<sp/>OPENBLAS_CORETYPE=ARMV8</highlight></codeline>
</programlisting></para>
</listitem></orderedlist>
</para>
<para><heading level="2">Open3D on Jetson</heading>
</para>
<para>Open3D is available pre-compiled for the jetson (<ulink url="http://www.open3d.org/docs/release/arm.html">details here</ulink>). Install via pip: <programlisting><codeline><highlight class="normal">apt-get<sp/>install<sp/>python3-pip</highlight></codeline>
<codeline><highlight class="normal">pip3<sp/>install<sp/>open3d==0.16.0</highlight></codeline>
</programlisting> <blockquote><para><zwj/>If version <computeroutput>0.16.0</computeroutput> is not available you need to upgrade your pip with <computeroutput>pip3 install -U pip</computeroutput>. You may additionally need to add the upgraded pip version to your path. </para>
</blockquote>View the mesh via: <programlisting><codeline><highlight class="normal">open3d<sp/>draw<sp/>mesh.ply</highlight></codeline>
</programlisting></para>
<para><heading level="1">Building for multiple GPU architectures</heading>
</para>
<para>By default, the library builds ONLY for the compute capability (CC) of the machine it&apos;s being built on. To build binaries that can be used across multiple machines (i.e., pre-built binaries for CI, for example), you can use the <computeroutput>BUILD_FOR_ALL_ARCHS</computeroutput> flag and set it to true. Example: <programlisting><codeline><highlight class="normal">cmake<sp/>..<sp/>-DBUILD_FOR_ALL_ARCHS=True<sp/>-DCMAKE_INSTALL_PREFIX=../install/<sp/>&amp;&amp;<sp/>make<sp/>-j8<sp/>&amp;&amp;<sp/>make<sp/>install</highlight></codeline>
</programlisting></para>
<para><heading level="1">Building redistributable binaries, with static dependencies</heading>
</para>
<para>If you want to include nvblox in another CMake project, simply <computeroutput>find_package(nvblox)</computeroutput> should bring in the correct libraries and headers. However, if you want to include it in a different build system such as Bazel, you can see the instructions here.</para>
<para><heading level="1">License</heading>
</para>
<para>This code is under an [open-source license](LICENSE) (Apache 2.0). :) </para>
    </detaileddescription>
    <location file="C:/Users/M502228/Downloads/nvblox-public/nvblox-public/README.md"/>
  </compounddef>
</doxygen>
